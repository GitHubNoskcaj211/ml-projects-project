{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../'))\n",
    "\n",
    "from evaluation.evaluation_harness import OnlineEvaluator, include_coldstart, include_all, score_time_spent, score_constant\n",
    "from statistical_test import estimate_probability_each_model_is_best\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.join(os.path.abspath(''), '../backend'))\n",
    "from backend.blueprints.recommendation import model_wrappers\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = OnlineEvaluator(include_all, score_constant)\n",
    "all_metrics = []\n",
    "def run_eval(model_name, model_save_path):\n",
    "    evaluator.reset(model_name, model_save_path)\n",
    "    # evaluator.plot_top_N_hit_percentage_percentiles(10)\n",
    "    evaluator.compute_top_N_hit_percentage(10)\n",
    "    # evaluator.plot_top_N_hit_percentage_percentiles(50)\n",
    "    evaluator.compute_top_N_hit_percentage(50)\n",
    "    # evaluator.plot_user_rank_roc_curve()\n",
    "    evaluator.compute_user_rank_auc_roc()\n",
    "    evaluator.compute_mean_positional_error()\n",
    "    # evaluator.save_metrics('test_online_evaluator', overwrite=True)\n",
    "    # pprint(evaluator.metrics)\n",
    "    all_metrics.append({'model_name': model_name, 'model_save_path': model_save_path, **evaluator.metrics})\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough samples for AUC ROC\n",
      "Not enough samples for AUC ROC\n",
      "Not enough samples for AUC ROC\n",
      "Not enough samples for AUC ROC\n",
      "Not enough samples for AUC ROC\n",
      "Not enough samples for AUC ROC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\akash\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "current_models = [(model_wrapper.definition().name(), model_wrapper.model_save_file_name)for model_wrapper in model_wrappers]\n",
    "# groups = evaluator.all_results.groupby(by=[\"rec_model_name\", \"rec_model_save_path\"])\n",
    "# for (model_name, model_save_path), data in groups:\n",
    "all_metrics = []\n",
    "for model_name, model_save_path in current_models:\n",
    "    run_eval(model_name, model_save_path)\n",
    "results = pd.DataFrame(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_probability_each_model_is_best(results, 'user_rank_auc_roc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_save_path</th>\n",
       "      <th>mean_positional_error</th>\n",
       "      <th>user_rank_auc_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neural_collaborative_filter_with_game_embeddings</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neural_collaborative_filter</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>collborative_filter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>non_linear_collaborative_filter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>multilayer_perceptron</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>collborative_filter_with_game_embeddings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>non_linear_collaborative_filter_with_game_embe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>multilayer_perceptron_with_game_embeddings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model_save_path  mean_positional_error  \\\n",
       "12   neural_collaborative_filter_with_game_embeddings               0.000000   \n",
       "8                         neural_collaborative_filter               1.428571   \n",
       "5                                 collborative_filter                    NaN   \n",
       "6                     non_linear_collaborative_filter                    NaN   \n",
       "7                               multilayer_perceptron                    NaN   \n",
       "9            collborative_filter_with_game_embeddings                    NaN   \n",
       "10  non_linear_collaborative_filter_with_game_embe...                    NaN   \n",
       "11         multilayer_perceptron_with_game_embeddings                    NaN   \n",
       "\n",
       "    user_rank_auc_roc  \n",
       "12           0.900000  \n",
       "8            0.416667  \n",
       "5                 NaN  \n",
       "6                 NaN  \n",
       "7                 NaN  \n",
       "9                 NaN  \n",
       "10                NaN  \n",
       "11                NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_names = {'evaluation_test_cf_low_weight_decay_increased_lr': 'collborative_filter', 'evaluation_test_gcf_low_weight_decay_increased_lr': 'non_linear_collaborative_filter', 'evaluation_test_mlp_low_weight_decay_increased_lr': 'multilayer_perceptron', 'evaluation_test_ncf_low_weight_decay_increased_lr': 'neural_collaborative_filter', 'evaluation_test_cf_embed_all_except_tags_genres': 'collborative_filter_with_game_embeddings', 'evaluation_test_gcf_embed_all_except_tags_genres': 'non_linear_collaborative_filter_with_game_embeddings', 'evaluation_test_mlp_embed_all_except_tags_genres': 'multilayer_perceptron_with_game_embeddings', 'evaluation_test_ncf_embed_all_except_tags_genres': 'neural_collaborative_filter_with_game_embeddings'}\n",
    "df = results.loc[results['model_save_path'].isin(evaluation_names), ['model_save_path', 'mean_positional_error', 'user_rank_auc_roc']].copy()\n",
    "df['model_save_path'] = df['model_save_path'].map(evaluation_names)\n",
    "display(df.sort_values(by='user_rank_auc_roc', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project_3.11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
